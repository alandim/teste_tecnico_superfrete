# teste_tecnico_superfrete

Como Engenheiro(a) de dados você atuará desenvolvendo pipelines de dados e constituirá
parte fundamental na construção de integrações de dados e disponibilização dos mesmos.
O objetivo deste case se baseia em construir uma solução escalável, de ponta a ponta,
partindo das fontes de dados até a entrega dos mesmos utilizando uma arquitetura de dados
de sua escolha, que comporte escalonamento eficiente e consumos cada vez maiores de
dados. Como desafio, proponha
1. Desenhar em uma arquitetura de dados (Big Data) completa utilizando plataforma cloud
que achar melhor. Neste desenho é necessário conter explicações sobre critérios e
motivos de escolha dos elementos da arquitetura.
Importante: este desenho deve considerar o uso do Airflow.
2. Desenvolver os códigos para um pipeline completo de ponta a ponta utilizando Airflow,
com atualizações em batch, considerando arquitetura que escolheu previamente na etapa
anterior com separação entre camadas, partindo da camada inicial até a camada de
entrega dos dados.
Importante: Os códigos não precisam ser implementados, apenas é solicitado que envie o
link do repositório com códigos desenvolvidos para que seu conhecimento possa ser
avaliado. Caso opte por deixá-lo em uma versão implementável, fique à vontade para
usar docker ou outra ferramenta de sua escolha, contudo é solicitado apenas que possa
rodar localmente e a documentação de sua implementação seja detalhada no repositório.
